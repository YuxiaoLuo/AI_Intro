{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f90efb10",
   "metadata": {},
   "source": [
    "# Hands-on Session for Customized Image Mining 2\n",
    "\n",
    "Credit to: [Youngeui Kim](https://cis.appstate.edu/directory/youngeui-kim-phd), [Yuxiao (Rain) Luo](https://yuxiaoluo.github.io)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YuxiaoLuo/AI_Intro/blob/main/week11_Customized_ImageMining_2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d158eb04",
   "metadata": {},
   "source": [
    "## Step 1: Create your folders and save image data respectively\n",
    "\n",
    "- create train data directories\n",
    "- create validation data directories\n",
    "\n",
    "See the graph below:\n",
    "```\n",
    "/train/\n",
    "    /Positive/\n",
    "        positive1.jpeg\n",
    "        positive2.jpeg\n",
    "    /Negative/\n",
    "        negative1.jpeg\n",
    "        negative2.jpeg\n",
    "/val/\n",
    "    /Positive/\n",
    "        positive1.jpeg\n",
    "        positive2.jpeg\n",
    "    /Negative/\n",
    "        negative1.jpeg\n",
    "        negative2.jpeg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d6b59",
   "metadata": {},
   "source": [
    "- Download the files needed for model training: https://github.com/YuxiaoLuo/AI_Intro/tree/main/data/customized_image_mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8086b555",
   "metadata": {},
   "source": [
    "If you are using Google Colab, mount your google drive to Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43644ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d49d59",
   "metadata": {},
   "source": [
    "## Step 2: Data loading and Data Generating diversifying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92220bd",
   "metadata": {},
   "source": [
    "- If you are using Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb0043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "train_dir = '/content/drive/MyDrive/train'\n",
    "val_dir = '/content/drive/MyDrive/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad282c",
   "metadata": {},
   "source": [
    "- If you run it locally, change your folder path accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d1aa121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "train_dir = '/data/customized_image_mining/train'\n",
    "val_dir = '/data/customized_image_mining/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f2497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,  # Use VGG16 preprocessing\n",
    "    rotation_range=30,                        # Augmentation: Random rotations\n",
    "    width_shift_range=0.2,                    # Augmentation: Horizontal shifts\n",
    "    height_shift_range=0.2,                   # Augmentation: Vertical shifts\n",
    "    shear_range=0.2,                          # Augmentation: Shearing\n",
    "    zoom_range=0.2,                           # Augmentation: Zooming\n",
    "    horizontal_flip=True,                     # Augmentation: Flipping\n",
    "    fill_mode='nearest'                       # Fill missing pixels after transformations\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Load data from directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),                   # Resize images to 224x224 (VGG16 input size)\n",
    "    batch_size=32,                            # Number of images per batch\n",
    "    class_mode='categorical'                  # Labels are categorical\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Check the classes\n",
    "print(train_generator.class_indices)  # {'Negative': 0, 'Positive': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70fae7",
   "metadata": {},
   "source": [
    "## Step 3: Customize the VGG16 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd24c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load VGG16 base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Global average pooling\n",
    "x = Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "predictions = Dense(2, activation='softmax')(x)  # Output layer with 2 classes\n",
    "\n",
    "# Create the full model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42fa3c5",
   "metadata": {},
   "source": [
    "## Step 4: Train the Custom Layers & Save the customized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1cc8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators for training and validation\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/content/drive/MyDrive/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    '/content/drive/MyDrive/val',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('/content/drive/MyDrive/custom_vgg16_sentiment_model.h5')\n",
    "Step 5-1: Applying the Customized Model to Your Data\n",
    "--- Once trained, we can apply the model as follows:\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Load the customized model\n",
    "model = load_model('/content/drive/MyDrive/custom_vgg16_sentiment_model.h5')\n",
    "\n",
    "# Function to preprocess and predict\n",
    "def predict_sentiment(img_path):\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = preprocess_input(np.expand_dims(img_array, axis=0))\n",
    "    prediction = model.predict(img_array)\n",
    "    sentiment_labels = ['Negative', 'Positive']\n",
    "    return sentiment_labels[np.argmax(prediction)], np.max(prediction)\n",
    "\n",
    "\n",
    "# Predict on a new (individual) image\n",
    "sentiment, confidence = predict_sentiment('/content/drive/MyDrive/image.jpg')\n",
    "print(f\"Sentiment: {sentiment}, Confidence: {confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b663feb6",
   "metadata": {},
   "source": [
    "## Step 5-2 (1) : Applying the Customized Model to Your Bulk Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Load the customized model\n",
    "model = load_model('/content/drive/MyDrive/custom_vgg16_sentiment_model.h5')\n",
    "\n",
    "\n",
    "# Function to predict sentiment\n",
    "def predict_sentiment(img_path):\n",
    "    img = load_img(img_path, target_size=(224, 224))  # Resize image to 224x224\n",
    "    img_array = img_to_array(img)                     # Convert to array\n",
    "    img_array = preprocess_input(np.expand_dims(img_array, axis=0))  # Preprocess for VGG16\n",
    "    prediction = model.predict(img_array)             # Predict with the model\n",
    "    sentiment_labels = ['Negative', 'Positive']       # Define labels\n",
    "    return sentiment_labels[np.argmax(prediction)], np.max(prediction)  # Return sentiment and confidence\n",
    "\n",
    "\n",
    "# checking the data\n",
    "df = pd.read_csv('/content/drive/MyDrive/ReviewData_updated.csv', encoding='ISO-8859-1')\n",
    "filtered_data = df.dropna(subset=['Image'])\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b13b3",
   "metadata": {},
   "source": [
    "## Step 5-2 (2) : Applying the Customized Model to Your Bulk Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40892d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load my data to predict\n",
    "if __name__ == \"__main__\":\n",
    "    # Load image metadata\n",
    "    df = pd.read_csv('/content/drive/MyDrive/ReviewData_updated.csv', encoding='ISO-8859-1')\n",
    "    filtered_data = df.dropna(subset=['Image'])\n",
    "\n",
    "    # Initialize variables for results\n",
    "    sentiment_counts = {'Negative': 0, 'Positive': 0}\n",
    "    predicted_sentiments = []\n",
    "    image_names = []\n",
    "    confidences = []\n",
    "\n",
    "    # Process each image\n",
    "    for index, row in filtered_data.iterrows():\n",
    "        image_name = str(int(row['Image']))\n",
    "        img_path = f'/content/drive/MyDrive/bulk/{image_name}.jpeg'\n",
    "\n",
    "        try:\n",
    "            # Predict sentiment for the image\n",
    "            sentiment, confidence = predict_sentiment(img_path)\n",
    "\n",
    "            # Store results\n",
    "            predicted_sentiments.append(sentiment)\n",
    "            image_names.append(image_name)\n",
    "            confidences.append(confidence)\n",
    "\n",
    "            # Update sentiment counts\n",
    "            if sentiment in sentiment_counts:\n",
    "                sentiment_counts[sentiment] += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_name}: {e}\")\n",
    "\n",
    "    # Print sentiment counts\n",
    "    print(\"Sentiment Counts:\")\n",
    "    for sentiment, count in sentiment_counts.items():\n",
    "        print(f\"{sentiment}: {count}\")\n",
    "\n",
    "    # Create a results DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'image_name': image_names,\n",
    "        'predicted_sentiment': predicted_sentiments,\n",
    "        'confidence': confidences\n",
    "    })\n",
    "\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df.to_csv('/content/drive/MyDrive/ReviewData_updated_With_Image.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89a6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
